{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "pd.set_option('display.float_format', '{:.3f}'.format)\n",
    "x_min, x_max = -1., 1.\n",
    "y_min, y_max = -.3, .3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(100547,), (100547,), (100547,), (100548,)]\n",
      "[(33516,), (33516,), (33516,), (33515,)]\n"
     ]
    }
   ],
   "source": [
    "trn_index_list = np.load(\"../input/eyn-original/trn_index_list.npy\", allow_pickle=True)\n",
    "val_index_list = np.load(\"../input/eyn-original/val_index_list.npy\", allow_pickle=True)\n",
    "print([np.shape(trn_index_list[i]) for i in range(np.shape(trn_index_list)[0])])\n",
    "print([np.shape(val_index_list[i]) for i in range(np.shape(val_index_list)[0])])\n",
    "train_targets_inside = np.load(\"../input/eyn-original/train_targets_inside.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2815323, 23) (703815, 23)\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_pickle(\"../input/eyn-pre-unravel-df/df_train.pickle\")\n",
    "df_test = pd.read_pickle(\"../input/eyn-pre-unravel-df/df_test.pickle\")\n",
    "print(df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat_col = ['entry_in', 'exit_in', 'clus_entry', 'clus_exit', 'tid_0', 'tid_1']\n",
    "cat_col = ['entry_in', 'exit_in', 'tid_0', 'tid_1']\n",
    "df_train[cat_col] = df_train[cat_col].astype('category')\n",
    "df_test[cat_col] = df_test[cat_col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_col = (['x_exit_0', 'y_exit_0', 'vmean_0', 'vmax_0', 'vmin_0', \n",
    "             'exit_in_0', 'dist_0', 'speed_0', 'dir_x_0', 'dir_y_0', 'clus_exit_0'] + \n",
    "            ['clus_entry_'+ str(i) for i in range(21)] + \n",
    "            ['clus_exit_'+ str(i) for i in range(1,21)])\n",
    "drop_col = []  # not dropping any columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "# pylint: disable = invalid-name, C0111\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, log_loss\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score\n",
    "\n",
    "def scoring_package(y_true, y_pred):\n",
    "    y_pred_class = np.array([k > 0.5 for k in y_pred])\n",
    "    f1 = f1_score(y_true, y_pred_class)\n",
    "    precision = precision_score(y_true, y_pred_class)\n",
    "    recall = recall_score(y_true, y_pred_class)\n",
    "    roc = roc_auc_score(y_true, y_pred)\n",
    "    return f1, precision, recall, roc\n",
    "\n",
    "target = np.load(\"../input/eyn-original/train_targets.npy\")\n",
    "y_label_x = target[:, 0]\n",
    "y_label_y = target[:, 1]\n",
    "\n",
    "binary = np.load(\"../input/eyn-original/train_targets_inside.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_embedding = np.load(\"../input/eynembedding/train_lstm.npy\")\n",
    "test_embedding = np.load(\"../input/eynembedding/test_lstm.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "time_dummy = []\n",
    "for i in df_train[\"t_entry\"]:\n",
    "    entry = np.repeat(0, 16)\n",
    "    if math.isnan(i):\n",
    "        time_dummy.append([np.nan]*16)\n",
    "    else:\n",
    "        num = int((i + 1.5) // 0.1)\n",
    "        if num != 0:\n",
    "            entry[num-1] = 1\n",
    "        time_dummy.append(entry)\n",
    "        \n",
    "time_dummy = np.array(time_dummy)\n",
    "# df_train_unstack = df_train.unstack()\n",
    "# unstack_col_names = [\"_\".join([tup[0],str(tup[1])]) for tup in df_train_unstack.columns.values]\n",
    "# df_train_unstack.columns = unstack_col_names\n",
    "# df_train_unstack = df_train_unstack.drop(drop_col, axis=1)\n",
    "# df_train_unstack.head()\n",
    "df_train_unstack = df_train.values\n",
    "df_train_unstack = np.concatenate([df_train_unstack, time_dummy], axis=1)\n",
    "# df_train_unstack = df_train_unstack.reshape((int(df_train_unstack.shape[0]/21), 43*21))\n",
    "df_train_unstack = df_train_unstack.reshape((int(df_train_unstack.shape[0]/21), 39*21))\n",
    "df_train_unstack = np.concatenate([df_train_unstack, trn_embedding], axis=1)\n",
    "\n",
    "import math\n",
    "time_dummy = []\n",
    "for i in df_test[\"t_entry\"]:\n",
    "    entry = np.repeat(0, 16)\n",
    "    if math.isnan(i):\n",
    "        time_dummy.append([np.nan]*16)\n",
    "    else:\n",
    "        num = int((i + 1.5) // 0.1)\n",
    "        if num != 0:\n",
    "            entry[num-1] = 1\n",
    "        time_dummy.append(entry)\n",
    "        \n",
    "df_test[cat_col] = df_test[cat_col].astype('category')\n",
    "# df_test_unstack = df_test.values\n",
    "# df_test_unstack = np.concatenate([df_test_unstack, time_dummy], axis=1)\n",
    "# df_test_unstack = df_test_unstack.reshape((int(df_test_unstack.shape[0]/21), 39*21))\n",
    "# df_test_unstack = df_test.unstack()\n",
    "# df_test_unstack.columns = unstack_col_names\n",
    "# df_test_unstack = df_test_unstack.drop(drop_col, axis=1)\n",
    "# df_test_unstack = df_test_unstack.values\n",
    "# df_test_unstack = np.concatenate([df_test_unstack, test_embedding], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10, random_state=0)\n",
    "indexes = kf.split(df_train_unstack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 0, hash: 78\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[100]\ttraining's binary_logloss: 0.104995\tvalid_1's binary_logloss: 0.14024\n",
      "Early stopping, best iteration is:\n",
      "[108]\ttraining's binary_logloss: 0.103266\tvalid_1's binary_logloss: 0.140148\n",
      "Training fold 1, hash: 78\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[100]\ttraining's binary_logloss: 0.105393\tvalid_1's binary_logloss: 0.140155\n",
      "Early stopping, best iteration is:\n",
      "[120]\ttraining's binary_logloss: 0.10106\tvalid_1's binary_logloss: 0.139896\n",
      "Training fold 2, hash: 78\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[100]\ttraining's binary_logloss: 0.105496\tvalid_1's binary_logloss: 0.140022\n",
      "Early stopping, best iteration is:\n",
      "[85]\ttraining's binary_logloss: 0.109333\tvalid_1's binary_logloss: 0.139776\n",
      "Training fold 3, hash: 78\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[100]\ttraining's binary_logloss: 0.105743\tvalid_1's binary_logloss: 0.139965\n",
      "Early stopping, best iteration is:\n",
      "[119]\ttraining's binary_logloss: 0.101349\tvalid_1's binary_logloss: 0.139815\n",
      "Training fold 4, hash: 78\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[100]\ttraining's binary_logloss: 0.105372\tvalid_1's binary_logloss: 0.140694\n",
      "Early stopping, best iteration is:\n",
      "[145]\ttraining's binary_logloss: 0.0964706\tvalid_1's binary_logloss: 0.140347\n",
      "Training fold 5, hash: 78\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[100]\ttraining's binary_logloss: 0.104892\tvalid_1's binary_logloss: 0.139744\n",
      "Early stopping, best iteration is:\n",
      "[90]\ttraining's binary_logloss: 0.10721\tvalid_1's binary_logloss: 0.139665\n",
      "Training fold 6, hash: 78\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[100]\ttraining's binary_logloss: 0.105537\tvalid_1's binary_logloss: 0.140211\n",
      "Early stopping, best iteration is:\n",
      "[94]\ttraining's binary_logloss: 0.107162\tvalid_1's binary_logloss: 0.140094\n",
      "Training fold 7, hash: 78\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[100]\ttraining's binary_logloss: 0.105664\tvalid_1's binary_logloss: 0.139351\n",
      "Early stopping, best iteration is:\n",
      "[95]\ttraining's binary_logloss: 0.106911\tvalid_1's binary_logloss: 0.139339\n",
      "Training fold 8, hash: 78\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[100]\ttraining's binary_logloss: 0.105132\tvalid_1's binary_logloss: 0.140018\n",
      "Early stopping, best iteration is:\n",
      "[98]\ttraining's binary_logloss: 0.105605\tvalid_1's binary_logloss: 0.139938\n",
      "Training fold 9, hash: 78\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[100]\ttraining's binary_logloss: 0.10525\tvalid_1's binary_logloss: 0.139802\n",
      "Early stopping, best iteration is:\n",
      "[109]\ttraining's binary_logloss: 0.103102\tvalid_1's binary_logloss: 0.139436\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'append' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-b6ae37e4f318>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0mpred_cate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0my_pred_full_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred_full_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0mvalid_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred_full_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m     \u001b[0mtest_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_cate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pred_cate.npy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'append' is not defined"
     ]
    }
   ],
   "source": [
    "num_boost_round = 300\n",
    "\n",
    "valid_ = []\n",
    "test_pred = []\n",
    "for trn_index, val_index in indexes:\n",
    "    # inputs: train_pd, train_targets_inside, and test_pd\n",
    "    # probably try https://lightgbm.readthedocs.io/en/latest/Python-API.html#lightgbm.cv, but cluster complications\n",
    "    y_pred_full_x = []\n",
    "    test_preds = []\n",
    "\n",
    "    for fold_num, i in enumerate(range(10)):\n",
    "        x_trn = df_train_unstack\n",
    "        binary_trn = binary\n",
    "\n",
    "        # create dataset for lightgbm\n",
    "        lgb_train_x = lgb.Dataset(x_trn, binary_trn)\n",
    "        #     lgb_train_y = lgb.Dataset(x_trn, y_trn_y)\n",
    "        #     lgb_eval_y = lgb.Dataset(x_val, y_val_y, reference=lgb_train_y)\n",
    "        params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "        'num_leaves': 63,\n",
    "        'learning_rate': 0.05,  # dynamic one below\n",
    "        'feature_fraction': 0.9,\n",
    "        'bagging_fraction': 0.9,\n",
    "        'bagging_freq': 5,\n",
    "        'verbose': 0,\n",
    "        'lambda': 0.1,\n",
    "        'num_threads': 3,\n",
    "        'seed': 42+fold_num\n",
    "        }\n",
    "\n",
    "        print(\"Training fold {}, hash: {}\".format(fold_num, np.sum(val_index)%999))\n",
    "\n",
    "        x_trn = df_train_unstack[trn_index]\n",
    "        x_val = df_train_unstack[val_index]\n",
    "\n",
    "        binary_val = binary[val_index]\n",
    "        binary_trn = binary[trn_index]\n",
    "\n",
    "        # create dataset for lightgbm\n",
    "        lgb_train_x = lgb.Dataset(x_trn, binary_trn)\n",
    "        lgb_eval_x = lgb.Dataset(x_val, binary_val, reference=lgb_train_x)\n",
    "        #     lgb_train_y = lgb.Dataset(x_trn, y_trn_y)\n",
    "        #     lgb_eval_y = lgb.Dataset(x_val, y_val_y, reference=lgb_train_y)\n",
    "\n",
    "        gbm_x = lgb.train(params,\n",
    "                        lgb_train_x,\n",
    "                        valid_sets=[lgb_train_x, lgb_eval_x],\n",
    "                        num_boost_round=num_boost_round,\n",
    "                        early_stopping_rounds=20,\n",
    "                        learning_rates=lambda iter: 0.1 * (0.995 ** iter),\n",
    "                        verbose_eval=100)\n",
    "\n",
    "        y_pred_x = gbm_x.predict(x_val, num_iteration=gbm_x.best_iteration)\n",
    "        y_pred_full_x.append(y_pred_x)\n",
    "\n",
    "        df_test_unstack = df_test.values\n",
    "        df_test_unstack = np.concatenate([df_test_unstack, time_dummy], axis=1)\n",
    "        df_test_unstack = df_test_unstack.reshape((int(df_test_unstack.shape[0]/21), 39*21))\n",
    "        df_test_unstack = np.concatenate([df_test_unstack, test_embedding], axis=1)\n",
    "\n",
    "        test_pred_x = gbm_x.predict(df_test_unstack, num_iteration=gbm_x.best_iteration).reshape(df_test_unstack.shape[0], 1)\n",
    "        #     test_pred_y = gbm_y.predict(df_test_unstack, num_iteration=gbm_y.best_iteration).reshape(df_test_unstack.shape[0], 1)\n",
    "        #     test_preds.append(np.concatenate([test_pred_x, test_pred_y], axis=1))\n",
    "        test_preds.append(test_pred_x)\n",
    "    pred_cate = np.average(test_preds, axis=0)\n",
    "    y_pred_full_x = np.average(y_pred_full_x, axis=0)\n",
    "    valid_,append(y_pred_full_x)\n",
    "    test_pred.append(pred_cate)\n",
    "np.save(\"pred_cate.npy\", test_pred)\n",
    "np.save(\"valid_pred.npy\", valid_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_boost_round = 300\n",
    "\n",
    "# # inputs: train_pd, train_targets_inside, and test_pd\n",
    "# # probably try https://lightgbm.readthedocs.io/en/latest/Python-API.html#lightgbm.cv, but cluster complications\n",
    "# y_pred_full_x = []\n",
    "# test_preds = []\n",
    "\n",
    "# for fold_num, i in enumerate(range(10)):\n",
    "#     x_trn = df_train_unstack\n",
    "#     binary_trn = binary\n",
    "    \n",
    "#     # create dataset for lightgbm\n",
    "#     lgb_train_x = lgb.Dataset(x_trn, binary_trn)\n",
    "# #     lgb_train_y = lgb.Dataset(x_trn, y_trn_y)\n",
    "# #     lgb_eval_y = lgb.Dataset(x_val, y_val_y, reference=lgb_train_y)\n",
    "#     params = {\n",
    "#     'boosting_type': 'goss',\n",
    "#     'objective': 'binary',\n",
    "#     'metric': 'binary_logloss',\n",
    "#     'num_leaves': 63,\n",
    "#     'learning_rate': 0.05,  # dynamic one below\n",
    "#     'feature_fraction': 0.9,\n",
    "#     'verbose': 0,\n",
    "#     'lambda': 0.1,\n",
    "#     'num_threads': 3,\n",
    "#     'seed': 42+fold_num\n",
    "# #     'histogram_pool_size' : 2048  # to restrict memory usage\n",
    "# #     'boost_from_average' : False  # as per warning message\n",
    "# }\n",
    "    \n",
    "#     print(\"Training fold {}, hash: {}\".format(fold_num, np.sum(val_index)%999))\n",
    "    \n",
    "#     x_trn = df_train_unstack[trn_index]\n",
    "#     x_val = df_train_unstack[val_index]\n",
    "    \n",
    "#     binary_val = binary[val_index]\n",
    "#     binary_trn = binary[trn_index]\n",
    "    \n",
    "#     # create dataset for lightgbm\n",
    "#     lgb_train_x = lgb.Dataset(x_trn, binary_trn)\n",
    "#     lgb_eval_x = lgb.Dataset(x_val, binary_val, reference=lgb_train_x)\n",
    "# #     lgb_train_y = lgb.Dataset(x_trn, y_trn_y)\n",
    "# #     lgb_eval_y = lgb.Dataset(x_val, y_val_y, reference=lgb_train_y)\n",
    "    \n",
    "#     gbm_x = lgb.train(params,\n",
    "#                     lgb_train_x,\n",
    "#                     valid_sets=[lgb_train_x, lgb_eval_x],\n",
    "#                     num_boost_round=num_boost_round,\n",
    "#                     early_stopping_rounds=20,\n",
    "#                     learning_rates=lambda iter: 0.1 * (0.995 ** iter),\n",
    "#                     verbose_eval=100)\n",
    "    \n",
    "# #     gbm_y = lgb.train(params,\n",
    "# #                     lgb_train_y,\n",
    "# #                     valid_sets=[lgb_train_y, lgb_eval_y],\n",
    "# #                     num_boost_round=num_boost_round,\n",
    "# #                     verbose_eval=100)\n",
    "\n",
    "#     # eval\n",
    "    \n",
    "# #     y_pred_ = np.copy(y_pred)\n",
    "#     y_pred_x = gbm_x.predict(x_val, num_iteration=gbm_x.best_iteration)\n",
    "#     y_pred_full_x.append(y_pred_x)\n",
    "    \n",
    "# #     y_pred_y = gbm_y.predict(x_val, num_iteration=gbm_y.best_iteration)\n",
    "# #     train_pred_y = gbm_y.predict(x_trn, num_iteration=gbm_y.best_iteration).reshape(trn_index.shape[0], 1)\n",
    "# #     y_pred_full_y[val_index] = y_pred_y\n",
    "# #     y_pred_y = y_pred_y.reshape(val_index.shape[0], 1)\n",
    "    \n",
    "# #     y_pred = np.concatenate([y_pred_x, y_pred_y], axis=1)\n",
    "# #     trn_pred = np.concatenate([train_pred_x, train_pred_y], axis=1)\n",
    "# #     pred_cate = compare(y_pred, binary_val, fold_num)\n",
    "# #     pred_cate = compare(trn_pred, binary_trn, fold_num)\n",
    "\n",
    "#     print('The F1-PC-RC-ROC of full prediction is: {:.5f}-{:.5f}-{:.5f}-{:.5f}'\n",
    "#        .format(*scoring_package(binary_trn, train_pred_x)))\n",
    "    \n",
    "#     print('The F1-PC-RC-ROC of full prediction is: {:.5f}-{:.5f}-{:.5f}-{:.5f}'\n",
    "#        .format(*scoring_package(binary_val, y_pred_x)))\n",
    "    \n",
    "#     # testing\n",
    "# #     df_test[\"clus_entry\"] = test_query_entry[fold_num].ravel()  # different fold have different cluster entries\n",
    "# #     df_test[\"clus_exit\"] = test_query_exit[fold_num].ravel()\n",
    "# #     df_test[\"clus_entry_w\"] = test_query_entry_w[fold_num].ravel()  # different fold have different cluster entries\n",
    "# #     df_test[\"clus_exit_w\"] = test_query_exit_w[fold_num].ravel()\n",
    "    \n",
    "#     df_test_unstack = df_test.values\n",
    "#     df_test_unstack = np.concatenate([df_test_unstack, time_dummy], axis=1)\n",
    "#     df_test_unstack = df_test_unstack.reshape((int(df_test_unstack.shape[0]/21), 39*21))\n",
    "#     df_test_unstack = np.concatenate([df_test_unstack, test_embedding], axis=1)\n",
    "    \n",
    "#     test_pred_x = gbm_x.predict(df_test_unstack, num_iteration=gbm_x.best_iteration).reshape(df_test_unstack.shape[0], 1)\n",
    "# #     test_pred_y = gbm_y.predict(df_test_unstack, num_iteration=gbm_y.best_iteration).reshape(df_test_unstack.shape[0], 1)\n",
    "# #     test_preds.append(np.concatenate([test_pred_x, test_pred_y], axis=1))\n",
    "#     test_preds.append(test_pred_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_cate = np.average(test_preds, axis=0)\n",
    "# y_pred_full_x = np.average(y_pred_full_x, axis=0)\n",
    "# np.save(\"pred_cate_1.npy\", pred_cate)\n",
    "# np.save(\"valid_pred_1.npy\", y_pred_full_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_boost_round = 600\n",
    "\n",
    "# # inputs: train_pd, train_targets_inside, and test_pd\n",
    "# # probably try https://lightgbm.readthedocs.io/en/latest/Python-API.html#lightgbm.cv, but cluster complications\n",
    "# y_pred_full_x = []\n",
    "# test_preds = []\n",
    "\n",
    "# for fold_num, i in enumerate(range(10)):\n",
    "#     x_trn = df_train_unstack\n",
    "#     binary_trn = binary\n",
    "    \n",
    "#     # create dataset for lightgbm\n",
    "#     lgb_train_x = lgb.Dataset(x_trn, binary_trn)\n",
    "# #     lgb_train_y = lgb.Dataset(x_trn, y_trn_y)\n",
    "# #     lgb_eval_y = lgb.Dataset(x_val, y_val_y, reference=lgb_train_y)\n",
    "#     params = {\n",
    "#     'boosting_type': 'dart',\n",
    "#     'objective': 'binary',\n",
    "#     'metric': 'binary_logloss',\n",
    "#     'num_leaves': 63,\n",
    "#     'learning_rate': 0.1,  # dynamic one below\n",
    "#     'feature_fraction': 0.9,\n",
    "#     'verbose': 0,\n",
    "#     'lambda': 0.1,\n",
    "#     'num_threads': 3,\n",
    "#     'seed': 42+fold_num\n",
    "# #     'histogram_pool_size' : 2048  # to restrict memory usage\n",
    "# #     'boost_from_average' : False  # as per warning message\n",
    "# }\n",
    "    \n",
    "#     print(\"Training fold {}, hash: {}\".format(fold_num, np.sum(val_index)%999))\n",
    "    \n",
    "#     x_trn = df_train_unstack[trn_index]\n",
    "#     x_val = df_train_unstack[val_index]\n",
    "    \n",
    "#     binary_val = binary[val_index]\n",
    "#     binary_trn = binary[trn_index]\n",
    "    \n",
    "#     # create dataset for lightgbm\n",
    "#     lgb_train_x = lgb.Dataset(x_trn, binary_trn)\n",
    "#     lgb_eval_x = lgb.Dataset(x_val, binary_val, reference=lgb_train_x)\n",
    "# #     lgb_train_y = lgb.Dataset(x_trn, y_trn_y)\n",
    "# #     lgb_eval_y = lgb.Dataset(x_val, y_val_y, reference=lgb_train_y)\n",
    "    \n",
    "#     gbm_x = lgb.train(params,\n",
    "#                     lgb_train_x,\n",
    "#                     valid_sets=[lgb_train_x, lgb_eval_x],\n",
    "#                     num_boost_round=num_boost_round,\n",
    "#                     verbose_eval=100)\n",
    "    \n",
    "# #     gbm_y = lgb.train(params,\n",
    "# #                     lgb_train_y,\n",
    "# #                     valid_sets=[lgb_train_y, lgb_eval_y],\n",
    "# #                     num_boost_round=num_boost_round,\n",
    "# #                     verbose_eval=100)\n",
    "\n",
    "#     # eval\n",
    "    \n",
    "# #     y_pred_ = np.copy(y_pred)\n",
    "#     y_pred_x = gbm_x.predict(x_val, num_iteration=gbm_x.best_iteration)\n",
    "#     y_pred_full_x.append(y_pred_x)\n",
    "    \n",
    "# #     y_pred_y = gbm_y.predict(x_val, num_iteration=gbm_y.best_iteration)\n",
    "# #     train_pred_y = gbm_y.predict(x_trn, num_iteration=gbm_y.best_iteration).reshape(trn_index.shape[0], 1)\n",
    "# #     y_pred_full_y[val_index] = y_pred_y\n",
    "# #     y_pred_y = y_pred_y.reshape(val_index.shape[0], 1)\n",
    "    \n",
    "# #     y_pred = np.concatenate([y_pred_x, y_pred_y], axis=1)\n",
    "# #     trn_pred = np.concatenate([train_pred_x, train_pred_y], axis=1)\n",
    "# #     pred_cate = compare(y_pred, binary_val, fold_num)\n",
    "# #     pred_cate = compare(trn_pred, binary_trn, fold_num)\n",
    "\n",
    "#     print('The F1-PC-RC-ROC of full prediction is: {:.5f}-{:.5f}-{:.5f}-{:.5f}'\n",
    "#        .format(*scoring_package(binary_trn, train_pred_x)))\n",
    "    \n",
    "#     print('The F1-PC-RC-ROC of full prediction is: {:.5f}-{:.5f}-{:.5f}-{:.5f}'\n",
    "#        .format(*scoring_package(binary_val, y_pred_x)))\n",
    "    \n",
    "#     # testing\n",
    "# #     df_test[\"clus_entry\"] = test_query_entry[fold_num].ravel()  # different fold have different cluster entries\n",
    "# #     df_test[\"clus_exit\"] = test_query_exit[fold_num].ravel()\n",
    "# #     df_test[\"clus_entry_w\"] = test_query_entry_w[fold_num].ravel()  # different fold have different cluster entries\n",
    "# #     df_test[\"clus_exit_w\"] = test_query_exit_w[fold_num].ravel()\n",
    "    \n",
    "#     df_test_unstack = df_test.values\n",
    "#     df_test_unstack = np.concatenate([df_test_unstack, time_dummy], axis=1)\n",
    "#     df_test_unstack = df_test_unstack.reshape((int(df_test_unstack.shape[0]/21), 39*21))\n",
    "#     df_test_unstack = np.concatenate([df_test_unstack, test_embedding], axis=1)\n",
    "    \n",
    "#     test_pred_x = gbm_x.predict(df_test_unstack, num_iteration=gbm_x.best_iteration).reshape(df_test_unstack.shape[0], 1)\n",
    "# #     test_pred_y = gbm_y.predict(df_test_unstack, num_iteration=gbm_y.best_iteration).reshape(df_test_unstack.shape[0], 1)\n",
    "# #     test_preds.append(np.concatenate([test_pred_x, test_pred_y], axis=1))\n",
    "#     test_preds.append(test_pred_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_cate = np.average(test_preds, axis=0)\n",
    "# y_pred_full_x = np.average(y_pred_full_x, axis=0)\n",
    "# np.save(\"pred_cate_2.npy\", pred_cate)\n",
    "# np.save(\"valid_pred_2.npy\", y_pred_full_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_preds_ = np.concatenate([np.average(test_preds[:, :, 0], axis=0).reshape(test_preds.shape[1], 1), np.average(test_preds[:, :, 1], axis=0).reshape(test_preds.shape[1], 1)], axis=1)\n",
    "# pred_cate = []\n",
    "# for i, j in enumerate(test_preds_):\n",
    "#     incity = whether_in_city(denormalize_x(j[0]), denormalize_y(j[1]))\n",
    "#     pred_cate.append(incity)\n",
    "# pred_cate = np.array(pred_cate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit = pd.read_csv(\"../input/ey-nextwave/data_test/data_test.csv\")\n",
    "df_submit = df_submit[df_submit['x_exit'].isnull()]\n",
    "df_submit = df_submit[['trajectory_id']].copy()\n",
    "df_submit = df_submit.rename(columns = {'trajectory_id':'id'})\n",
    "df_submit['target'] = pred_cate\n",
    "df_submit.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>traj_00032f51796fd5437b238e3a9823d13d_31_5</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>traj_000479418b5561ab694a2870cc04fd43_25_10</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>traj_000506a39775e5bca661ac80e3f466eb_29_5</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>traj_0005401ceddaf27a9b7f0d42ef1fbe95_1_4</td>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>traj_00063a4f6c12e1e4de7d876580620667_3_4</td>\n",
       "      <td>0.081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            id  target\n",
       "0   traj_00032f51796fd5437b238e3a9823d13d_31_5   0.007\n",
       "1  traj_000479418b5561ab694a2870cc04fd43_25_10   0.006\n",
       "2   traj_000506a39775e5bca661ac80e3f466eb_29_5   0.995\n",
       "3    traj_0005401ceddaf27a9b7f0d42ef1fbe95_1_4   0.021\n",
       "4    traj_00063a4f6c12e1e4de7d876580620667_3_4   0.081"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submit = pd.read_csv(\"submission.csv\")\n",
    "df_submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33510</th>\n",
       "      <td>traj_ffe98f6e0adf12f9c7b51c4e9607a87a_15_13</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33511</th>\n",
       "      <td>traj_fff607ecd3f8d3dcb65791e8b4c22a5f_3_25</td>\n",
       "      <td>0.581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33512</th>\n",
       "      <td>traj_fff813b56230c2f026f783f5b9f9ca90_19_0</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33513</th>\n",
       "      <td>traj_fff9400843a88c3bfe52e7ce8bf97316_19_17</td>\n",
       "      <td>0.023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33514</th>\n",
       "      <td>traj_fff9552047b095e8242b4913f3289a26_25_7</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                id  target\n",
       "33510  traj_ffe98f6e0adf12f9c7b51c4e9607a87a_15_13   0.001\n",
       "33511   traj_fff607ecd3f8d3dcb65791e8b4c22a5f_3_25   0.581\n",
       "33512   traj_fff813b56230c2f026f783f5b9f9ca90_19_0   0.002\n",
       "33513  traj_fff9400843a88c3bfe52e7ce8bf97316_19_17   0.023\n",
       "33514   traj_fff9552047b095e8242b4913f3289a26_25_7   0.001"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submit.tail()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
